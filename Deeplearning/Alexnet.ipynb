{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNkxSxJudALazZtPAQ3+63t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install tensorboardX"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2juVs-gER31Q","executionInfo":{"status":"ok","timestamp":1695963125082,"user_tz":-540,"elapsed":4197,"user":{"displayName":"Saijang Pang","userId":"15343919118935749390"}},"outputId":"5c13b9b2-9499-4a1a-cebc-54f1b7b89a00"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorboardX\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6.2.2\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"kjY6dEWaPXZq","executionInfo":{"status":"ok","timestamp":1695963126800,"user_tz":-540,"elapsed":394,"user":{"displayName":"Saijang Pang","userId":"15343919118935749390"}}},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils import data\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from tensorboardX import SummaryWriter\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":["# model parameters 정의하기\n","NUM_EPOCHS = 90\n","BATCH_SIZE = 128\n","MOMENTUM = 0.9\n","LR_DECAY = 0.0005\n","LR_INIT = 0.01\n","IMAGE_DIM = 227 # pixels\n","NUM_CLASSES = 1000\n","DEVICE_IDS = [0, 1, 2, 3]"],"metadata":{"id":"ifc1obaxRyFS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data directory 지정하기\n","INPUT_ROOT_DIR = 'alexnet_data_in'\n","TRAIN_IMG_DIR = 'alexnet_data_in/imagenet'\n","OUTPUT_DIR = 'alexnet_data_out'\n","LOG_DIR = OUTPUT_DIR + '/tblogs'  # tensorboard logs\n","CHECKPOINT_DIR = OUTPUT_DIR + '/models'  # model checkpoints\n","\n","# checkpoint 경로 directory 만들기\n","os.makedirs(CHECKPOINT_DIR, exist_ok=True)"],"metadata":{"id":"-tqsjRfsR9xv","executionInfo":{"status":"ok","timestamp":1695963169069,"user_tz":-540,"elapsed":234,"user":{"displayName":"Saijang Pang","userId":"15343919118935749390"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class AlexNet(nn.Module):\n","  def __init__(self, num_classes=1000):\n","    super.__init__()\n","    self.net = nn.Sequential(\n","        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),\n","        nn.ReLU(),\n","        nn.LocalResponseNorm(size=5, alpha=0.0001, beta= 0.75, k=2),\n","        nn.MaxPool2d(kernel_size=3, stride=2),\n","        nn.Conv2d(96,256,5,padding=2),\n","        nn.ReLU(),\n","        nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n","        nn.MaxPool2d(kernel_size=3, stride=2),\n","        nn.Conv2d(256, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n","        nn.ReLU(),\n","        nn.Conv2d(384, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n","        nn.ReLU(),\n","        nn.Conv2d(384, 256, 3, padding=1),  # (b x 256 x 13 x 13)\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6))\n","    )\n","    self.classifier = nn.Sequential(\n","        nn.Dropout(p=0.5, inplace=True),\n","        nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n","        nn.ReLU(),\n","        nn.Dropout(p=0.5, inplace=True),\n","        nn.Linear(in_features=4096, out_features=4096),\n","        nn.ReLU(),\n","        nn.Linear(in_features=4096, out_features=num_classes),\n","        )\n","\n","    self.init_bias()\n","    def init_bias(self):\n","      for layer in self.net:\n","        if isinstance(layer, nn.Conv2d):\n","          nn.init.normal_(layer.bias, 0)\n","      nn.init.constant_(self.net[4].bias, 1)\n","      nn.init.constant_(self.net[10].bias, 1)\n","      nn.init.constant_(self.net[12].bias, 1)\n","    def forward(self,x):\n","      x = self.net(x)\n","      x = x.view(-1,256*6*6)\n","      return self.classfier(x)"],"metadata":{"id":"NcWxFsL5SD4v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","  seed = torch.initial_seed()\n","  print(\"used seed : {}\".format(seed))\n","\n","  tbwriter = SummaryWriter(log_dir = LOG_DIR)\n","\n","  alexnet = AlexNet(num_classes= NUM_CLASSES).to(device)\n","  alexnet = torch.nn.parallel.DataParallel(alexnet, device_ids=DEVICE_IDS)\n","\n","  dataset = datasets.ImageFolder(TRAIN_IMG_DIR,\n","                                 transforms.Compose(\n","                                    [transforms.CenterCrop(IMAGE_DIM),\n","                                     transforms.ToTensor(),\n","                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","                                    ]))\n","  dataloader = data.DataLoader(\n","      dataset,\n","      shuffle=True,\n","      pin_memory=True,\n","      num_workers=8,\n","      drop_last=True,\n","      batch_size=BATCH_SIZE\n","  )\n","  optimizer = optim.SGD(\n","      params=alexnet.parameters(),\n","      lr=LR_INIT,\n","      momentum=MOMENTUM,\n","      weight_decay=LR_DECAY\n","  )\n","  lr_scheduler= optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n","  total_steps=1\n","  for epoch in range(NUM_EPOCHS):\n","    lr_scheduler.step()\n","    for imgs, classes in dataloader:\n","      imgs, classes = imgs.to(device), classes.to(device)\n","      output = alexnet(imgs)\n","      loss = F.cross_entropy(output,classes)\n","\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      # log the information and add to tensorboard\n","      # 정보를 기록하고 tensorboard에 추가하기\n","      if total_steps % 10 == 0:\n","        with torch.no_grad():\n","          _, preds = torch.max(output, 1)\n","          accuracy = torch.sum(preds == classes)\n","\n","          print('Epoch: {} \\tStep: {} \\tLoss: {:.4f} \\tAcc: {}'\n","                .format(epoch + 1, total_steps, loss.item(), accuracy.item()))\n","          tbwriter.add_scalar('loss', loss.item(), total_steps)\n","          tbwriter.add_scalar('accuracy', accuracy.item(), total_steps)\n","\n","      # gradient values와 parameter average values 추력하기\n","      if total_steps % 100 == 0:\n","        with torch.no_grad():\n","          for name, parameter in alexnet.named_parameters():\n","            if parameter.grad is not None:\n","              avg_grad = torch.mean(parameter.grad)\n","              print('\\t{} - grad_avg: {}'.format(name, avg_grad))\n","              tbwriter.add_scalar('grad_avg/{}'.format(name), avg_grad.item(), total_steps)\n","              tbwriter.add_histogram('grad/{}'.format(name),parameter.grad.cpu().numpy(), total_steps)\n","              if parameter.data is not None:\n","                avg_weight = torch.mean(parameter.data)\n","                print('\\t{} - param_avg: {}'.format(name, avg_weight))\n","                tbwriter.add_histogram('weight/{}'.format(name),parameter.data.cpu().numpy(), total_steps)\n","                tbwriter.add_scalar('weight_avg/{}'.format(name), avg_weight.item(), total_steps)\n","\n","      total_steps += 1\n","\n","    # checkpoints 저장하기\n","    checkpoint_path = os.path.join(CHECKPOINT_DIR, 'alexnet_states_e{}.pkl'.format(epoch + 1))\n","    state = {\n","              'epoch': epoch,\n","            'total_steps': total_steps,\n","            'optimizer': optimizer.state_dict(),\n","            'model': alexnet.state_dict(),\n","            'seed': seed,\n","        }\n","    torch.save(state, checkpoint_path)"],"metadata":{"id":"W_rsQu9kU3RA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"llXeF_NiU3I1"},"execution_count":null,"outputs":[]}]}