{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMueAdfwnswwVMTqTaRmGqK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BNY4o5nwbQMY","executionInfo":{"status":"ok","timestamp":1696133378142,"user_tz":-540,"elapsed":24633,"user":{"displayName":"Saijang Pang","userId":"15343919118935749390"}},"outputId":"bb6ef995-ec8b-4e23-f782-546a3fdc8f2d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GP3oGORrbF4k"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.utils import transforms\n","\n","class ConvBlock(nn.Module):\n","  def __init__(self, in_channels, out_channels, **kwargs)-> None:\n","    super(ConvBlock, self).__init__()\n","    self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n","    self.batchnorm = nn.BatchNorm2d(out_channels)\n","    self.relu = nn.ReLU()\n","  def forward(self, x:Tensor) -> Tensor:\n","    x = self.conv(x)\n","    x = self.batchnorm(x)\n","    x = self.relu(x)\n","    return x"]},{"cell_type":"code","source":["class Inception(nn.Module):\n","  def __init__(self, in_channels, n1x1, n3x3_reduce, n3x3, n5x5_reduce, n5x5, pool_proj)->None:\n","    super(Inception,self).__init__()\n","    self.branch1 = ConvBlock(in_channels, n1x1, kernel_size = 1, stride=1, padding=0)\n","\n","    self.branch2 = nn.Sequential(\n","        ConvBlock(in_channels, n3x3_reduce, kernel_size=1, stride=1, padding=0),\n","        ConvBlock(n3x3_reduce, n3x3, kernel_size=3, stride=1, padding=1))\n","\n","    self.branch3 = nn.Sequential(\n","        ConvBlock(in_channels, n5x5_reduce, kernel_size=1, stride=1, padding=0),\n","        ConvBlock(n5x5_reduce, n5x5, kernel_size=5, stride=1, padding=2))\n","\n","    self.branch4 = nn.Sequential(\n","        nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n","        ConvBlock(in_channels, pool_proj, kernel_size=1, stride=1, padding=0))\n","  def forward(self, x:Tensor)->Tensor:\n","    x1 = self.branch1(x)\n","    x2 = self.branch2(x)\n","    x3 = self.branch3(x)\n","    x4 = self.branch4(x)\n","    return torch.cat([x1,x2,x3,x4], dim=1)"],"metadata":{"id":"sL48DBBdbQzd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class InceptionAux(nn.Module):\n","  def __init__(self, in_channels, num_classes) -> None:\n","    super(InceptionAux, self).__init__()\n","    self.avgpool = nn.AvgPool2d(kernel_size=5, stride=3)\n","    self.conv = ConvBlock(in_channels, 128, kernel_size=1, stride=1, padding=0)\n","    self.fc1 = nn.Linear(2048, 1024)\n","    self.fc2 = nn.Linear(1024, num_classes)\n","    self.dropout = nn.Dropout(p=0.7)\n","    self.relu = nn.ReLU()\n","\n","  def forward(self, x: Tensor) -> Tensor:\n","    x = self.avgpool(x)\n","    x = self.conv(x)\n","    x = x.view(x.size()[0], -1)\n","    x = self.fc1(x)\n","    x = self.relu(x)\n","    x = self.dropout(x)\n","    x = self.fc2(x)\n","    return x"],"metadata":{"id":"MFbWPbFHdEko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class GoogLeNet(nn.Module):\n","    def __init__(self, aux_logits=True, num_classes=1000) -> None:\n","        super(GoogLeNet, self).__init__()\n","        assert aux_logits == True or aux_logits == False\n","        self.aux_logits = aux_logits\n","\n","        self.conv1 = ConvBlock(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)\n","        self.conv2 = ConvBlock(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0)\n","        self.conv3 = ConvBlock(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1)\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n","\n","        self.a3 = Inception(192, 64, 96, 128, 16, 32, 32)\n","        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n","        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)\n","        self.a4 = Inception(480, 192, 96, 208, 16, 48, 64)\n","        self.b4 = Inception(512, 160, 112, 224, 24, 64, 64)\n","        self.c4 = Inception(512, 128, 128, 256, 24, 64, 64)\n","        self.d4 = Inception(512, 112, 144, 288, 32, 64, 64)\n","        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n","        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n","        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.dropout = nn.Dropout(p=0.4)\n","        self.linear = nn.Linear(1024, num_classes)\n","\n","        if self.aux_logits:\n","            self.aux1 = InceptionAux(512, num_classes)\n","            self.aux2 = InceptionAux(528, num_classes)\n","        else:\n","            self.aux1 = None\n","            self.aux2 = None\n","\n","    def transform_input(self, x: Tensor) -> Tensor:\n","        x_R = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n","        x_G = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n","        x_B = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n","        x = torch.cat([x_R, x_G, x_B], 1)\n","        return x\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        x = self.transform_input(x)\n","\n","        x = self.conv1(x)\n","        x = self.maxpool1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.maxpool2(x)\n","        x = self.a3(x)\n","        x = self.b3(x)\n","        x = self.maxpool3(x)\n","        x = self.a4(x)\n","        aux1: Optional[Tensor] = None\n","        if self.aux_logits and self.training:\n","            aux1 = self.aux1(x)\n","\n","        x = self.b4(x)\n","        x = self.c4(x)\n","        x = self.d4(x)\n","        aux2: Optional[Tensor] = None\n","        if self.aux_logits and self.training:\n","            aux2 = self.aux2(x)\n","\n","        x = self.e4(x)\n","        x = self.maxpool4(x)\n","        x = self.a5(x)\n","        x = self.b5(x)\n","        x = self.avgpool(x)\n","        x = x.view(x.shape[0], -1) # x = x.reshape(x.shape[0], -1)\n","        x = self.linear(x)\n","        x = self.dropout(x)\n","\n","        if self.aux_logits and self.training:\n","            return aux1, aux2\n","        else:\n","            return x"],"metadata":{"id":"r3drUjZcd3Ro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    x = torch.randn(3, 3, 224, 224)\n","    model = GoogLeNet(aux_logits=True, num_classes=1000)\n","    print (model(x)[1].shape)"],"metadata":{"id":"vZ6CCN_EeB2L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import torch\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import argparse\n","from googlenet import GoogLeNet\n","\n","def load_dataset():\n","    # preprocess\n","    transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    # load train, test data\n","    train = datasets.CIFAR10(root=\"../data\", train=True, transform=transform, download=True)\n","    test = datasets.CIFAR10(root=\"../data\", train=False, transform=transform, download=True)\n","    train_loader = DataLoader(train, batch_size=args.batch_size, shuffle=True)\n","    test_loader = DataLoader(test, batch_size=args.batch_size, shuffle=False)\n","    return train_loader, test_loader\n","\n","\n","if __name__ == \"__main__\":\n","    # set hyperparameter\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--batch_size', action='store', type=int, default=100)\n","    parser.add_argument('--learning_rate', action='store', type=float, default='0.0002')\n","    parser.add_argument('--n_epochs', action='store', type=int, default=100)\n","    parser.add_argument('--plot', action='store', type=bool, default=True)\n","    args = parser.parse_args()\n","    np.random.seed(1)\n","    seed = torch.manual_seed(1)\n","\n","    # load dataset\n","    train_loader, test_loader = load_dataset()\n","\n","    # model, loss, optimizer\n","    losses = []\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = GoogLeNet(aux_logits=False, num_classes=10).to(device)\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n","\n","    # train\n","    for epoch in range(args.n_epochs):\n","        model.train()\n","        train_loss = 0\n","        correct, count = 0, 0\n","        for batch_idx, (images, labels) in enumerate(train_loader, start=1):\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            output = model.forward(images)\n","            loss = criterion(output, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            _, preds = torch.max(output, 1)\n","            count += labels.size(0)\n","            correct += preds.eq(labels).sum().item() # torch.sum(preds == labels)\n","\n","            if batch_idx % 100 == 0:\n","                print (f\"[*] Epoch: {epoch} \\tStep: {batch_idx}/{len(train_loader)}\\tTrain accuracy: {round((correct/count), 4)} \\tTrain Loss: {round((train_loss/count)*100, 4)}\")\n","\n","        # valid\n","        model.eval()\n","        correct, count = 0, 0\n","        valid_loss = 0\n","        with torch.no_grad():\n","            for batch_idx, (images, labels) in enumerate(test_loader, start=1):\n","                images, labels = images.to(device), labels.to(device)\n","                output = model.forward(images)\n","                loss = criterion(output, labels)\n","                valid_loss += loss.item()\n","                _, preds = torch.max(output, 1)\n","                count += labels.size(0)\n","                correct += preds.eq(labels).sum().item() # torch.sum(preds == labels)\n","                if batch_idx % 100 == 0:\n","                    print (f\"[*] Step: {batch_idx}/{len(test_loader)}\\tValid accuracy: {round((correct/count), 4)} \\tValid Loss: {round((valid_loss/count)*100, 4)}\")\n","\n"],"metadata":{"id":"DQkvvZzpeG3E"},"execution_count":null,"outputs":[]}]}